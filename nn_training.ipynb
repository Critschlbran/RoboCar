{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Module import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset import using opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for the image import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 100\n",
    "img_height = 40\n",
    "\n",
    "train_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped'\n",
    "validation_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 18777 images and labels. This might take a while, please wait...\n",
      "Progress 100 %\n",
      "Loaded 18777 images and 18777 labels from directory /mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped\n",
      "Loaded images have shape (40, 100, 3).\n"
     ]
    }
   ],
   "source": [
    "train_labels, train_images = dataset_utils.load_dataset(path_to_dataset = train_dataset_path, change_contrast = True, grayscale = True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1812 images and labels. This might take a while, please wait...\n",
      "Progress 100 %\n",
      "Loaded 1812 images and 1812 labels from directory /mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped\n",
      "Loaded images have shape (40, 100, 3).\n"
     ]
    }
   ],
   "source": [
    "validation_labels, validation_images = dataset_utils.load_dataset(path_to_dataset = validation_dataset_path, change_contrast = True, grayscale = True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Construct the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 100, 3)\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (img_height, img_width)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "print(IMG_SHAPE)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV3Small(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the custom classification layer to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 40, 100, 3)]      0         \n",
      "                                                                 \n",
      " MobilenetV3small (Function  (None, 2, 4, 576)         939120    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                147488    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1086707 (4.15 MB)\n",
      "Trainable params: 147587 (576.51 KB)\n",
      "Non-trainable params: 939120 (3.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# new layers\n",
    "global_average_layer = tf.keras.layers.Flatten()\n",
    "dense_layer_1 = tf.keras.layers.Dense(32, activation='elu')\n",
    "prediction_layer = tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "\n",
    "\n",
    "# construct the final model\n",
    "inputs = keras.Input(shape = (img_height, img_width, 3))\n",
    "x = keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = dense_layer_1(x)\n",
    "#x = keras.layers.Dropout(0.05)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4608)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-3].output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Start the initial learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.03\n",
    "initial_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the before built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch == 0:\n",
    "        return lr\n",
    "    elif epoch % 5 == 0:\n",
    "        return lr * 0.9 \n",
    "    else: \n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 04:51:37.208123: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-23 04:51:39.127299: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f9f211bfc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-23 04:51:39.127362: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 4GB Laptop GPU, Compute Capability 8.6\n",
      "2024-05-23 04:51:39.182800: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716432699.401473   10437 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 22s 23ms/step - loss: 0.6766 - accuracy: 0.8785 - val_loss: 0.1656 - val_accuracy: 0.9404 - lr: 0.0300\n",
      "Epoch 2/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1955 - accuracy: 0.9324 - val_loss: 0.1387 - val_accuracy: 0.9547 - lr: 0.0300\n",
      "Epoch 3/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1785 - accuracy: 0.9358 - val_loss: 0.2245 - val_accuracy: 0.9205 - lr: 0.0300\n",
      "Epoch 4/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.4016 - accuracy: 0.8234 - val_loss: 0.4110 - val_accuracy: 0.6004 - lr: 0.0300\n",
      "Epoch 5/30\n",
      "586/586 [==============================] - 12s 21ms/step - loss: 0.2710 - accuracy: 0.9197 - val_loss: 0.2000 - val_accuracy: 0.9487 - lr: 0.0300\n",
      "Epoch 6/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.2718 - accuracy: 0.9304 - val_loss: 0.3120 - val_accuracy: 0.9415 - lr: 0.0300\n",
      "Epoch 7/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.2517 - accuracy: 0.9283 - val_loss: 0.4335 - val_accuracy: 0.8438 - lr: 0.0300\n",
      "Epoch 8/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1783 - accuracy: 0.9510 - val_loss: 0.1809 - val_accuracy: 0.9641 - lr: 0.0150\n",
      "Epoch 9/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1038 - accuracy: 0.9687 - val_loss: 0.2183 - val_accuracy: 0.9636 - lr: 0.0150\n",
      "Epoch 10/30\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 0.1245 - accuracy: 0.9661 - val_loss: 0.1530 - val_accuracy: 0.9625 - lr: 0.0150\n",
      "Epoch 11/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1133 - accuracy: 0.9680 - val_loss: 0.2208 - val_accuracy: 0.9570 - lr: 0.0150\n",
      "Epoch 12/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1324 - accuracy: 0.9682 - val_loss: 0.6852 - val_accuracy: 0.9443 - lr: 0.0150\n",
      "Epoch 13/30\n",
      "586/586 [==============================] - 12s 21ms/step - loss: 0.0844 - accuracy: 0.9769 - val_loss: 0.2008 - val_accuracy: 0.9630 - lr: 0.0075\n",
      "Epoch 14/30\n",
      "586/586 [==============================] - 14s 24ms/step - loss: 0.0749 - accuracy: 0.9770 - val_loss: 0.2372 - val_accuracy: 0.9625 - lr: 0.0075\n",
      "Epoch 15/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.2321 - val_accuracy: 0.9641 - lr: 0.0075\n",
      "Epoch 16/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.0718 - accuracy: 0.9786 - val_loss: 0.2544 - val_accuracy: 0.9614 - lr: 0.0075\n",
      "Epoch 17/30\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 0.0683 - accuracy: 0.9801 - val_loss: 0.1638 - val_accuracy: 0.9619 - lr: 0.0075\n",
      "Epoch 18/30\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 0.0559 - accuracy: 0.9834 - val_loss: 0.1758 - val_accuracy: 0.9614 - lr: 0.0037\n",
      "Epoch 19/30\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 0.0515 - accuracy: 0.9850 - val_loss: 0.2442 - val_accuracy: 0.9641 - lr: 0.0037\n",
      "Epoch 20/30\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 0.0527 - accuracy: 0.9845 - val_loss: 0.1757 - val_accuracy: 0.9597 - lr: 0.0037\n",
      "Epoch 21/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.1764 - val_accuracy: 0.9592 - lr: 0.0037\n",
      "Epoch 22/30\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 0.2360 - val_accuracy: 0.9641 - lr: 0.0037\n",
      "Epoch 23/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.0456 - accuracy: 0.9874 - val_loss: 0.1745 - val_accuracy: 0.9663 - lr: 0.0019\n",
      "Epoch 24/30\n",
      "586/586 [==============================] - 11s 20ms/step - loss: 0.0415 - accuracy: 0.9892 - val_loss: 0.1603 - val_accuracy: 0.9658 - lr: 0.0019\n",
      "Epoch 25/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 0.1770 - val_accuracy: 0.9647 - lr: 0.0019\n",
      "Epoch 26/30\n",
      "586/586 [==============================] - 12s 21ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.1954 - val_accuracy: 0.9658 - lr: 0.0019\n",
      "Epoch 27/30\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 0.0406 - accuracy: 0.9886 - val_loss: 0.1958 - val_accuracy: 0.9636 - lr: 0.0019\n",
      "Epoch 28/30\n",
      "586/586 [==============================] - 13s 21ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 0.1698 - val_accuracy: 0.9658 - lr: 9.3750e-04\n",
      "Epoch 29/30\n",
      "586/586 [==============================] - 14s 24ms/step - loss: 0.0375 - accuracy: 0.9902 - val_loss: 0.1726 - val_accuracy: 0.9647 - lr: 9.3750e-04\n",
      "Epoch 30/30\n",
      "586/586 [==============================] - 20s 34ms/step - loss: 0.0368 - accuracy: 0.9904 - val_loss: 0.1828 - val_accuracy: 0.9647 - lr: 9.3750e-04\n"
     ]
    }
   ],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=(validation_images, validation_labels), epochs=initial_epochs, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x = validation_images, y = validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine tuning the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all layers except for the uppermost layers of the base model. Layzers will be frozen from ***fine_tune_from*** to ***len(base_model.layers)***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 40, 100, 3)]      0         \n",
      "                                                                 \n",
      " MobilenetV3small (Function  (None, 2, 4, 576)         939120    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                147488    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1086707 (4.15 MB)\n",
      "Trainable params: 294096 (1.12 MB)\n",
      "Non-trainable params: 792611 (3.02 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_from = len(base_model.layers) - 25\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# don't train the dense layer\n",
    "model.layers[len(model.layers) - 1].trainable = False\n",
    "model.layers[len(model.layers) - 2].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model again but decrease the learning rate in order to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the uppermost layers of the base model and proceed where you left off in the initial training by using the last epoch of the first training as the initial epoch for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "586/586 [==============================] - 34s 43ms/step - loss: 0.1037 - accuracy: 0.9701 - val_loss: 0.2718 - val_accuracy: 0.9272 - lr: 3.0000e-04\n",
      "Epoch 31/40\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 0.0933 - accuracy: 0.9727 - val_loss: 0.1899 - val_accuracy: 0.9608 - lr: 3.0000e-04\n",
      "Epoch 32/40\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.0837 - accuracy: 0.9761 - val_loss: 0.1682 - val_accuracy: 0.9636 - lr: 3.0000e-04\n",
      "Epoch 33/40\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 0.0739 - accuracy: 0.9772 - val_loss: 0.1895 - val_accuracy: 0.9520 - lr: 3.0000e-04\n",
      "Epoch 34/40\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 0.0696 - accuracy: 0.9791 - val_loss: 0.1532 - val_accuracy: 0.9647 - lr: 3.0000e-04\n",
      "Epoch 35/40\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 0.0634 - accuracy: 0.9811 - val_loss: 0.1880 - val_accuracy: 0.9547 - lr: 3.0000e-04\n",
      "Epoch 36/40\n",
      "586/586 [==============================] - 28s 48ms/step - loss: 0.0595 - accuracy: 0.9817 - val_loss: 0.1544 - val_accuracy: 0.9636 - lr: 3.0000e-04\n",
      "Epoch 37/40\n",
      "586/586 [==============================] - 31s 53ms/step - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.1739 - val_accuracy: 0.9608 - lr: 3.0000e-04\n",
      "Epoch 38/40\n",
      "586/586 [==============================] - 24s 41ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.1635 - val_accuracy: 0.9619 - lr: 3.0000e-04\n",
      "Epoch 39/40\n",
      "586/586 [==============================] - 22s 38ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.1563 - val_accuracy: 0.9597 - lr: 3.0000e-04\n",
      "Epoch 40/40\n",
      "586/586 [==============================] - 20s 34ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.1816 - val_accuracy: 0.9647 - lr: 1.5000e-04\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "finetune_history = model.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=generator.flow(validation_images, validation_labels, batch_size), initial_epoch=history.epoch[-1], epochs=initial_epochs + 10, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finetune_history.history.keys())\n",
    "key = 'accuracy'\n",
    "for loss in history.history[key]:\n",
    "    print(loss, end='\\r\\n')\n",
    "for loss in finetune_history.history[key]:\n",
    "    print(loss, end='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save the model\n",
    "\n",
    "Info: Loading can be done via: ***model = tf.keras.models.load_model(PATH_TO_MODEL_FILE)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now until it is implemented properly: manually make sure that the path exists (in this case '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/')\n",
    "save_path = '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/mn3_w100_h40_crop_14_contrast_grayscale_96_val_99_train.keras'\n",
    "\n",
    "model.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
