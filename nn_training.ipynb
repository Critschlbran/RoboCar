{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Module import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 13:16:24.537624: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-21 13:16:24.866950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-21 13:16:24.867012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-21 13:16:24.874233: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-21 13:16:24.976067: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-21 13:16:26.473510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset import using opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for the image import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 100\n",
    "img_height = 40\n",
    "\n",
    "train_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped'\n",
    "validation_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 18777 images and labels. This might take a while, please wait...\n",
      "Progress 100 %\n",
      "Loaded 18777 images and 18777 labels from directory /mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped\n",
      "Loaded images have shape (40, 100, 3).\n"
     ]
    }
   ],
   "source": [
    "train_labels, train_images = dataset_utils.load_dataset(path_to_dataset = train_dataset_path, change_contrast = True, grayscale = True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1812 images and labels. This might take a while, please wait...\n",
      "Progress 100 %\n",
      "Loaded 1812 images and 1812 labels from directory /mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped\n",
      "Loaded images have shape (40, 100, 3).\n"
     ]
    }
   ],
   "source": [
    "validation_labels, validation_images = dataset_utils.load_dataset(path_to_dataset = validation_dataset_path, change_contrast = True, grayscale = True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Construct the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 100, 3)\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 13:18:25.642082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:25.906989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:25.907079: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:25.909220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:25.909278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:25.909298: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:26.644113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:26.644154: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:26.644160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-21 13:18:26.644181: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 13:18:26.644195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1756 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 4GB Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (img_height, img_width)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "print(IMG_SHAPE)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV3Small(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the custom classification layer to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 40, 100, 3)]      0         \n",
      "                                                                 \n",
      " MobilenetV3small (Function  (None, 2, 4, 576)         939120    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 576)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                18464     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957683 (3.65 MB)\n",
      "Trainable params: 18563 (72.51 KB)\n",
      "Non-trainable params: 939120 (3.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# new layers\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dense_layer_1 = tf.keras.layers.Dense(32, activation='elu')\n",
    "prediction_layer = tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "\n",
    "\n",
    "# construct the final model\n",
    "inputs = keras.Input(shape = (img_height, img_width, 3))\n",
    "x = keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = dense_layer_1(x)\n",
    "#x = keras.layers.Dropout(0.05)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Start the initial learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.03\n",
    "initial_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the before built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch == 0:\n",
    "        return lr\n",
    "    elif epoch % 5 == 0:\n",
    "        return lr * 0.9 \n",
    "    else: \n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 13:18:30.088165: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-21 13:18:30.927424: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f098546b1e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-21 13:18:30.927453: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 4GB Laptop GPU, Compute Capability 8.6\n",
      "2024-05-21 13:18:30.931402: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716290310.984423    8989 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 10s 13ms/step - loss: 0.3863 - accuracy: 0.8598 - val_loss: 0.1991 - val_accuracy: 0.9321 - lr: 0.0300\n",
      "Epoch 2/30\n",
      "586/586 [==============================] - 6s 10ms/step - loss: 0.2415 - accuracy: 0.9085 - val_loss: 0.1958 - val_accuracy: 0.9327 - lr: 0.0300\n",
      "Epoch 3/30\n",
      "586/586 [==============================] - 6s 11ms/step - loss: 0.2248 - accuracy: 0.9162 - val_loss: 0.2179 - val_accuracy: 0.9205 - lr: 0.0300\n",
      "Epoch 4/30\n",
      "586/586 [==============================] - 6s 11ms/step - loss: 0.2310 - accuracy: 0.9178 - val_loss: 0.1481 - val_accuracy: 0.9481 - lr: 0.0300\n",
      "Epoch 5/30\n",
      "586/586 [==============================] - 7s 13ms/step - loss: 0.2081 - accuracy: 0.9249 - val_loss: 0.2110 - val_accuracy: 0.9233 - lr: 0.0300\n",
      "Epoch 6/30\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 0.1931 - accuracy: 0.9305 - val_loss: 0.3051 - val_accuracy: 0.8753 - lr: 0.0300\n",
      "Epoch 7/30\n",
      "586/586 [==============================] - 9s 14ms/step - loss: 0.1834 - accuracy: 0.9342 - val_loss: 0.2317 - val_accuracy: 0.9156 - lr: 0.0300\n",
      "Epoch 8/30\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 0.1853 - accuracy: 0.9329 - val_loss: 0.1898 - val_accuracy: 0.9360 - lr: 0.0300\n",
      "Epoch 9/30\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 0.1895 - accuracy: 0.9334 - val_loss: 0.2660 - val_accuracy: 0.9089 - lr: 0.0300\n",
      "Epoch 10/30\n",
      "586/586 [==============================] - 8s 13ms/step - loss: 0.1416 - accuracy: 0.9494 - val_loss: 0.1368 - val_accuracy: 0.9608 - lr: 0.0150\n",
      "Epoch 11/30\n",
      "586/586 [==============================] - 7s 11ms/step - loss: 0.1420 - accuracy: 0.9490 - val_loss: 0.1634 - val_accuracy: 0.9487 - lr: 0.0150\n",
      "Epoch 12/30\n",
      "586/586 [==============================] - 8s 14ms/step - loss: 0.1353 - accuracy: 0.9516 - val_loss: 0.1477 - val_accuracy: 0.9547 - lr: 0.0150\n",
      "Epoch 13/30\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 0.1499 - accuracy: 0.9462 - val_loss: 0.1485 - val_accuracy: 0.9492 - lr: 0.0150\n",
      "Epoch 14/30\n",
      "586/586 [==============================] - 6s 10ms/step - loss: 0.1333 - accuracy: 0.9529 - val_loss: 0.1483 - val_accuracy: 0.9492 - lr: 0.0150\n",
      "Epoch 15/30\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 0.1262 - accuracy: 0.9569 - val_loss: 0.1515 - val_accuracy: 0.9498 - lr: 0.0150\n",
      "Epoch 16/30\n",
      "586/586 [==============================] - 8s 14ms/step - loss: 0.1078 - accuracy: 0.9635 - val_loss: 0.1685 - val_accuracy: 0.9459 - lr: 0.0075\n",
      "Epoch 17/30\n",
      "586/586 [==============================] - 8s 13ms/step - loss: 0.1089 - accuracy: 0.9630 - val_loss: 0.1322 - val_accuracy: 0.9586 - lr: 0.0075\n",
      "Epoch 18/30\n",
      "586/586 [==============================] - 10s 16ms/step - loss: 0.1048 - accuracy: 0.9640 - val_loss: 0.1424 - val_accuracy: 0.9570 - lr: 0.0075\n",
      "Epoch 19/30\n",
      "586/586 [==============================] - 7s 12ms/step - loss: 0.1062 - accuracy: 0.9637 - val_loss: 0.1788 - val_accuracy: 0.9432 - lr: 0.0075\n",
      "Epoch 20/30\n",
      "586/586 [==============================] - 8s 14ms/step - loss: 0.1058 - accuracy: 0.9637 - val_loss: 0.1442 - val_accuracy: 0.9581 - lr: 0.0075\n",
      "Epoch 21/30\n",
      "586/586 [==============================] - 10s 17ms/step - loss: 0.1069 - accuracy: 0.9627 - val_loss: 0.1537 - val_accuracy: 0.9564 - lr: 0.0075\n",
      "Epoch 22/30\n",
      "586/586 [==============================] - 7s 11ms/step - loss: 0.1043 - accuracy: 0.9645 - val_loss: 0.1688 - val_accuracy: 0.9481 - lr: 0.0075\n",
      "Epoch 23/30\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.1580 - val_accuracy: 0.9509 - lr: 0.0037\n",
      "Epoch 24/30\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 0.0930 - accuracy: 0.9691 - val_loss: 0.1479 - val_accuracy: 0.9547 - lr: 0.0037\n",
      "Epoch 25/30\n",
      "586/586 [==============================] - 7s 12ms/step - loss: 0.0924 - accuracy: 0.9686 - val_loss: 0.1539 - val_accuracy: 0.9520 - lr: 0.0037\n",
      "Epoch 26/30\n",
      "586/586 [==============================] - 9s 16ms/step - loss: 0.0912 - accuracy: 0.9691 - val_loss: 0.1413 - val_accuracy: 0.9636 - lr: 0.0037\n",
      "Epoch 27/30\n",
      "586/586 [==============================] - 8s 14ms/step - loss: 0.0928 - accuracy: 0.9687 - val_loss: 0.1462 - val_accuracy: 0.9536 - lr: 0.0037\n",
      "Epoch 28/30\n",
      "586/586 [==============================] - 7s 12ms/step - loss: 0.0859 - accuracy: 0.9714 - val_loss: 0.1843 - val_accuracy: 0.9376 - lr: 0.0019\n",
      "Epoch 29/30\n",
      "586/586 [==============================] - 9s 16ms/step - loss: 0.0865 - accuracy: 0.9708 - val_loss: 0.1474 - val_accuracy: 0.9547 - lr: 0.0019\n",
      "Epoch 30/30\n",
      "586/586 [==============================] - 10s 16ms/step - loss: 0.0851 - accuracy: 0.9710 - val_loss: 0.1488 - val_accuracy: 0.9558 - lr: 0.0019\n"
     ]
    }
   ],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=(validation_images, validation_labels), epochs=initial_epochs, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x = validation_images, y = validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine tuning the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all layers except for the uppermost layers of the base model. Layzers will be frozen from ***fine_tune_from*** to ***len(base_model.layers)***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 40, 100, 3)]      0         \n",
      "                                                                 \n",
      " MobilenetV3small (Function  (None, 2, 4, 576)         939120    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 576)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                18464     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957683 (3.65 MB)\n",
      "Trainable params: 294096 (1.12 MB)\n",
      "Non-trainable params: 663587 (2.53 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_from = len(base_model.layers) - 25\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# don't train the dense layer\n",
    "model.layers[len(model.layers) - 1].trainable = False\n",
    "model.layers[len(model.layers) - 2].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model again but decrease the learning rate in order to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the uppermost layers of the base model and proceed where you left off in the initial training by using the last epoch of the first training as the initial epoch for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "586/586 [==============================] - 31s 36ms/step - loss: 0.1644 - accuracy: 0.9462 - val_loss: 0.1671 - val_accuracy: 0.9470 - lr: 3.0000e-04\n",
      "Epoch 31/40\n",
      "586/586 [==============================] - 14s 24ms/step - loss: 0.1217 - accuracy: 0.9590 - val_loss: 0.1504 - val_accuracy: 0.9498 - lr: 3.0000e-04\n",
      "Epoch 32/40\n",
      "586/586 [==============================] - 14s 24ms/step - loss: 0.1033 - accuracy: 0.9650 - val_loss: 0.1980 - val_accuracy: 0.9376 - lr: 3.0000e-04\n",
      "Epoch 33/40\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 0.0926 - accuracy: 0.9686 - val_loss: 0.1848 - val_accuracy: 0.9404 - lr: 3.0000e-04\n",
      "Epoch 34/40\n",
      "586/586 [==============================] - 14s 24ms/step - loss: 0.0802 - accuracy: 0.9725 - val_loss: 0.1221 - val_accuracy: 0.9658 - lr: 3.0000e-04\n",
      "Epoch 35/40\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 0.0726 - accuracy: 0.9757 - val_loss: 0.1277 - val_accuracy: 0.9625 - lr: 3.0000e-04\n",
      "Epoch 36/40\n",
      "586/586 [==============================] - 12s 21ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.1205 - val_accuracy: 0.9636 - lr: 3.0000e-04\n",
      "Epoch 37/40\n",
      "586/586 [==============================] - 13s 21ms/step - loss: 0.0561 - accuracy: 0.9813 - val_loss: 0.1717 - val_accuracy: 0.9498 - lr: 3.0000e-04\n",
      "Epoch 38/40\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 0.1188 - val_accuracy: 0.9696 - lr: 3.0000e-04\n",
      "Epoch 39/40\n",
      "586/586 [==============================] - 13s 22ms/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 0.1208 - val_accuracy: 0.9669 - lr: 3.0000e-04\n",
      "Epoch 40/40\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.1394 - val_accuracy: 0.9581 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "source": [
    "finetune_history = model.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=generator.flow(validation_images, validation_labels, batch_size), initial_epoch=history.epoch[-1], epochs=initial_epochs + 10, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finetune_history.history.keys())\n",
    "key = 'accuracy'\n",
    "for loss in history.history[key]:\n",
    "    print(loss, end='\\r\\n')\n",
    "for loss in finetune_history.history[key]:\n",
    "    print(loss, end='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save the model\n",
    "\n",
    "Info: Loading can be done via: ***model = tf.keras.models.load_model(PATH_TO_MODEL_FILE)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now until it is implemented properly: manually make sure that the path exists (in this case '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/')\n",
    "save_path = '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/mn3_w100_h40_crop_14_contrast_grayscale_96_val_99_train.keras'\n",
    "\n",
    "model.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
