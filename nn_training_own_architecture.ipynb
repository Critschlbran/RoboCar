{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Module import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset import using opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for the image import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 100\n",
    "img_height = 40\n",
    "\n",
    "train_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped'\n",
    "validation_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_images = dataset_utils.load_dataset(path_to_dataset = train_dataset_path, change_contrast = True, grayscale=True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels, validation_images = dataset_utils.load_dataset(path_to_dataset = validation_dataset_path, change_contrast = True, grayscale=True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[0][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "reshaped_train_images = []\n",
    "reshaped_val_images = []\n",
    "\n",
    "shape = train_images[0].shape\n",
    "\n",
    "for train_image_index in range(len(train_images)):\n",
    "    reshaped_train_images.append(np.reshape(train_images[train_image_index][:,:,1], (shape[0], shape[1], 1)))\n",
    "\n",
    "for validation_image_index in range(len(validation_images)):\n",
    "    reshaped_val_images.append(np.reshape(validation_images[validation_image_index][:,:,1], (shape[0], shape[1], 1)))\n",
    "\n",
    "reshaped_train_images = np.array(reshaped_train_images)\n",
    "reshaped_val_images = np.array(reshaped_val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Construct the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (img_height, img_width)\n",
    "IMG_SHAPE = IMG_SIZE + (1,)\n",
    "\n",
    "X_input = keras.layers.Input(IMG_SHAPE)\n",
    "\n",
    "# CONV -> BN -> RELU Block applied to X\n",
    "X = keras.layers.Conv2D(16, (3, 3), strides=(1, 1), name='conv0', padding='same')(X_input)\n",
    "X = keras.layers.MaxPooling2D((2, 2))(X)\n",
    "X = keras.layers.Conv2D(8, (5, 5), strides=(1, 1), name=\"conv2\", padding='same')(X)\n",
    "X = keras.layers.BatchNormalization(axis=3, name='bn0')(X)\n",
    "X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "# MAXPOOL\n",
    "X = keras.layers.MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "# FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "X = keras.layers.Flatten()(X)\n",
    "X = keras.layers.Dense(64, activation=\"selu\")(X)\n",
    "X = keras.layers.Dense(3, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "# Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "model = keras.models.Model(inputs=X_input, outputs=X, name='HappyModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the custom classification layer to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Start the initial learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.03\n",
    "initial_epochs = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the before built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(generator.flow(reshaped_train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=(reshaped_val_images, validation_labels), epochs=initial_epochs, callbacks=keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x = validation_images, y = validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save the model\n",
    "\n",
    "Info: Loading can be done via: ***model = tf.keras.models.load_model(PATH_TO_MODEL_FILE)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now until it is implemented properly: manually make sure that the path exists (in this case '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/')\n",
    "save_path = '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/happy_house_w100_h40_no_contrast_grayscale_train_99_val_97.keras'\n",
    "\n",
    "model.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
