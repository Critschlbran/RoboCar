{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Module import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset import using opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for the image import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 100\n",
    "img_height = 40\n",
    "\n",
    "train_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped'\n",
    "validation_dataset_path = r'/mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 18777 images and labels. This might take a while, please wait...\n",
      "Progress 100 %\n",
      "Loaded 18777 images and 18777 labels from directory /mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/training_dataset/all_cropped\n",
      "Loaded images have shape (40, 100, 3).\n"
     ]
    }
   ],
   "source": [
    "train_labels, train_images = dataset_utils.load_dataset(path_to_dataset = train_dataset_path, change_contrast = True, grayscale = True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1812 images and labels. This might take a while, please wait...\n",
      "Progress 100 %\n",
      "Loaded 1812 images and 1812 labels from directory /mnt/d/Dev/DHBW/DHBW_Studienarbeit/training_images/validation_dataset/all_cropped\n",
      "Loaded images have shape (40, 100, 3).\n"
     ]
    }
   ],
   "source": [
    "validation_labels, validation_images = dataset_utils.load_dataset(path_to_dataset = validation_dataset_path, change_contrast = True, grayscale = True, image_size = (img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Construct the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (img_height, img_width)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "base_model_v3 = tf.keras.applications.MobileNetV3Small(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model_v3.trainable = False\n",
    "\n",
    "base_model_v2 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model_v2.trainable = False\n",
    "\n",
    "base_model_v1 = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model_v1.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the custom classification layer to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 40, 100, 3)]      0         \n",
      "                                                                 \n",
      " MobilenetV3small (Function  (None, 2, 4, 576)         939120    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 13827     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952947 (3.64 MB)\n",
      "Trainable params: 13827 (54.01 KB)\n",
      "Non-trainable params: 939120 (3.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape = (img_height, img_width, 3))\n",
    "\n",
    "x = base_model_v3(inputs, training = False)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs_3 = tf.keras.layers.Dense(3, activation = 'softmax')(x)\n",
    "\n",
    "y = base_model_v2(inputs, training=False)\n",
    "y = tf.keras.layers.Flatten()(y)\n",
    "outputs_2 = tf.keras.layers.Dense(3, activation = 'softmax')(y)\n",
    "\n",
    "z = base_model_v1(inputs, training=False)\n",
    "z = tf.keras.layers.Flatten()(z)\n",
    "outputs_1 = tf.keras.layers.Dense(3, activation = 'softmax')(z)\n",
    "\n",
    "model_v1 = keras.Model(inputs, outputs_1)\n",
    "model_v2 = keras.Model(inputs, outputs_2)\n",
    "model_v3 = keras.Model(inputs, outputs_3)\n",
    "\n",
    "model_v3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Start the initial learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.03\n",
    "initial_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the before built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_v2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_v3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch == 0:\n",
    "        return lr\n",
    "    elif epoch % 5 == 0:\n",
    "        return lr * 0.9 \n",
    "    else: \n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "history_v1 = model_v1.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=(validation_images, validation_labels), epochs=initial_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_v2 = model_v2.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=(validation_images, validation_labels), epochs=initial_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 04:44:34.796788: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/586 [..............................] - ETA: 40:16 - loss: 2.3177 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 04:44:35.633582: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f08d11d1cd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-23 04:44:35.633635: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 4GB Laptop GPU, Compute Capability 8.6\n",
      "2024-05-23 04:44:35.639990: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716432275.713578  332638 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 16s 20ms/step - loss: 2.1908 - accuracy: 0.8852 - val_loss: 0.7557 - val_accuracy: 0.9465\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.4381 - accuracy: 0.9309 - val_loss: 1.2302 - val_accuracy: 0.9514\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.2747 - accuracy: 0.9438 - val_loss: 3.6912 - val_accuracy: 0.9100\n",
      "Epoch 4/10\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 1.5123 - accuracy: 0.9432 - val_loss: 1.3488 - val_accuracy: 0.9614\n",
      "Epoch 5/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.5022 - accuracy: 0.9501 - val_loss: 1.4819 - val_accuracy: 0.9614\n",
      "Epoch 6/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.1780 - accuracy: 0.9586 - val_loss: 4.4527 - val_accuracy: 0.8951\n",
      "Epoch 7/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.3992 - accuracy: 0.9549 - val_loss: 4.0123 - val_accuracy: 0.9200\n",
      "Epoch 8/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.1186 - accuracy: 0.9628 - val_loss: 2.3203 - val_accuracy: 0.9542\n",
      "Epoch 9/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.2127 - accuracy: 0.9610 - val_loss: 1.8263 - val_accuracy: 0.9658\n",
      "Epoch 10/10\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 1.1095 - accuracy: 0.9652 - val_loss: 2.5356 - val_accuracy: 0.9614\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history_v3 = model_v3.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=(validation_images, validation_labels), epochs=initial_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x = validation_images, y = validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine tuning the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all layers except for the uppermost layers of the base model. Layzers will be frozen from ***fine_tune_from*** to ***len(base_model.layers)***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_from = len(base_model.layers) - 25\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# don't train the dense layer\n",
    "model.layers[len(model.layers) - 1].trainable = False\n",
    "model.layers[len(model.layers) - 2].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model again but decrease the learning rate in order to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the uppermost layers of the base model and proceed where you left off in the initial training by using the last epoch of the first training as the initial epoch for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_history = model.fit(generator.flow(train_images, train_labels, batch_size), steps_per_epoch=len(train_images)/batch_size, validation_data=generator.flow(validation_images, validation_labels, batch_size), initial_epoch=history.epoch[-1], epochs=initial_epochs + 10, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finetune_history.history.keys())\n",
    "key = 'accuracy'\n",
    "for loss in history.history[key]:\n",
    "    print(loss, end='\\r\\n')\n",
    "for loss in finetune_history.history[key]:\n",
    "    print(loss, end='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save the model\n",
    "\n",
    "Info: Loading can be done via: ***model = tf.keras.models.load_model(PATH_TO_MODEL_FILE)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now until it is implemented properly: manually make sure that the path exists (in this case '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/')\n",
    "save_path = '/mnt/d/Dev/DHBW/DHBW_Studienarbeit/models/model_v3.keras'\n",
    "\n",
    "model_v3.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
